{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1759f18-ad7d-4645-a42f-a166b0435378",
   "metadata": {},
   "source": [
    "# [Lab4] SageMaker Training Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7886ee2b-5de9-4477-bfde-70c268bea385",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p pipeline_scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7694d98f-58f3-4c98-a61c-066410a4749c",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "029f7a55-42ba-4c0a-8ad1-47622f0822da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3 \n",
    "import pandas as pd \n",
    "import sagemaker \n",
    "from sagemaker.workflow.pipeline_context import PipelineSession \n",
    "\n",
    "s3_client = boto3.resource('s3') \n",
    "pipeline_name = f\"sagemaker-train-pipeline\" \n",
    "sagemaker_session = sagemaker.session.Session() \n",
    "region = sagemaker_session.boto_region_name \n",
    "role = sagemaker.get_execution_role() \n",
    "pipeline_session = PipelineSession() \n",
    "default_bucket = sagemaker_session.default_bucket() \n",
    "model_package_group_name = f\"ChurnModelPackageGroup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c45979-3228-4511-b29d-3a7ce4a087c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ( \n",
    " ParameterInteger, \n",
    " ParameterString, \n",
    " ParameterFloat) \n",
    "\n",
    "auc_score_threshold = 0.75 \n",
    "base_job_prefix = \"churn-example\"\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "processing_instance_type = ParameterString( name=\"ProcessingInstanceType\", default_value=\"ml.m5.xlarge\") \n",
    "training_instance_type = ParameterString( name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\") \n",
    "input_data = \"storedata_total.csv\" \n",
    "model_approval_status = ParameterString( name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6518f736-fb1f-4998-8814-7ceb5c35dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data = pd.read_csv(\"storedata_total.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74badf70-4394-41c1-ba9f-38e370012d43",
   "metadata": {},
   "source": [
    "## 2. Processing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3439c726-2084-4b4e-bcc9-5090219a7c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pipeline_scripts/churn_preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"pipeline_scripts/churn_preprocess.py\"\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"/opt/ml/processing\"\n",
    "    #Read Data\n",
    "    df = pd.read_csv(\n",
    "        f\"{base_dir}/input/storedata_total.csv\"\n",
    "    )\n",
    "    # convert created column to datetime\n",
    "    df[\"created\"] = pd.to_datetime(df[\"created\"])\n",
    "    #Convert firstorder and lastorder to datetime datatype\n",
    "    df[\"firstorder\"] = pd.to_datetime(df[\"firstorder\"],errors='coerce')\n",
    "    df[\"lastorder\"] = pd.to_datetime(df[\"lastorder\"],errors='coerce')\n",
    "    #Drop Rows with Null Values\n",
    "    df = df.dropna()\n",
    "    #Create column which gives the days between the last order and the first order\n",
    "    df['first_last_days_diff'] = (df['lastorder'] - df['firstorder']).dt.days\n",
    "    #Create column which gives the days between the customer record was created and the first order\n",
    "    df['created_first_days_diff'] = (df['created'] - df['firstorder']).dt.days\n",
    "    #Drop columns\n",
    "    df.drop(['custid', 'created','firstorder','lastorder'], axis=1, inplace=True)\n",
    "    #Apply one hot encoding on favday and city columns\n",
    "    df = pd.get_dummies(df, prefix=['favday', 'city'], columns=['favday', 'city'])\n",
    "    # Split into train, validation and test datasets\n",
    "    y = df.pop(\"retained\")\n",
    "    X_pre = df\n",
    "    y_pre = y.to_numpy().reshape(len(y), 1)\n",
    "    X = np.concatenate((y_pre, X_pre), axis=1)\n",
    "    np.random.shuffle(X)\n",
    "    # Split in Train, Test and Validation Datasets\n",
    "    train, validation, test = np.split(X, [int(.7*len(X)), int(.85*len(X))])\n",
    "    train_rows = np.shape(train)[0]\n",
    "    validation_rows = np.shape(validation)[0]\n",
    "    test_rows = np.shape(test)[0]\n",
    "    train = pd.DataFrame(train)\n",
    "    test = pd.DataFrame(test)\n",
    "    validation = pd.DataFrame(validation)\n",
    "    # Convert the label column to integer\n",
    "    train[0] = train[0].astype(int)\n",
    "    test[0] = test[0].astype(int)\n",
    "    validation[0] = validation[0].astype(int)\n",
    "    # Save the Dataframes as csv files\n",
    "    train.to_csv(f\"{base_dir}/train/train.csv\", header=False, index=False)\n",
    "    validation.to_csv(f\"{base_dir}/validation/validation.csv\", header=False, index=False)\n",
    "    test.to_csv(f\"{base_dir}/test/test.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "548605ee-1d25-4dd0-98c5-2e0e8f3aea87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define Processing Step for Feature Engineering\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "framework_version = \"1.0-1\"\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-churn-process\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=[\n",
    "      ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),  \n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\",\\\n",
    "                         destination=f\"s3://{default_bucket}/output/train\" ),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\",\\\n",
    "                        destination=f\"s3://{default_bucket}/output/validation\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\",\\\n",
    "                        destination=f\"s3://{default_bucket}/output/test\")\n",
    "    ],\n",
    "    code=f\"pipeline_scripts/churn_preprocess.py\",\n",
    ")\n",
    "step_process = ProcessingStep(name=\"ChurnModelProcess\", step_args=processor_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0a9749-16a5-406c-8180-76153720c7e9",
   "metadata": {},
   "source": [
    "## 3. Training Step (Hyper Parameter Tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6938bdf-5dd2-4eb9-b0e2-90812ab03752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "\n",
    "# training step for generating model artifacts\n",
    "model_path = f\"s3://{default_bucket}/output\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.0-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "fixed_hyperparameters = {\n",
    "\"eval_metric\":\"auc\",\n",
    "\"objective\":\"binary:logistic\",\n",
    "\"num_round\":\"100\",\n",
    "\"rate_drop\":\"0.3\",\n",
    "\"tweedie_variance_power\":\"1.4\"\n",
    "}\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    hyperparameters=fixed_hyperparameters,\n",
    "    output_path=model_path,\n",
    "    base_job_name=f\"churn-train\",\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "788e7f30-70ac-412a-ae85-97965b29c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "\"eta\": ContinuousParameter(0, 1),\n",
    "\"min_child_weight\": ContinuousParameter(1, 10),\n",
    "\"alpha\": ContinuousParameter(0, 2),\n",
    "\"max_depth\": IntegerParameter(1, 10),\n",
    "}\n",
    "objective_metric_name = \"validation:auc\"\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    xgb_train,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=2,\n",
    ")\n",
    "\n",
    "hpo_args = tuner.fit(\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "step_tuning = TuningStep(\n",
    "    name=\"ChurnHyperParameterTuning\",\n",
    "    step_args=hpo_args,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567da70c-bd13-44a7-8d1e-49371ded0e29",
   "metadata": {},
   "source": [
    "## 4. Evalution Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6c349a0-9005-419c-b6e7-dbecfbde61ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pipeline_scripts/churn_evaluate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"pipeline_scripts/churn_evaluate.py\"\n",
    "\n",
    "import json\n",
    "import pathlib\n",
    "import pickle\n",
    "import tarfile\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "import datetime as dt\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "if __name__ == \"__main__\":   \n",
    "    #Read Model Tar File\n",
    "    model_path = f\"/opt/ml/processing/model/model.tar.gz\"\n",
    "    with tarfile.open(model_path) as tar:\n",
    "        tar.extractall(path=\".\")\n",
    "    model = pickle.load(open(\"xgboost-model\", \"rb\"))\n",
    "    #Read Test Data using which we evaluate the model\n",
    "    test_path = \"/opt/ml/processing/test/test.csv\"\n",
    "    df = pd.read_csv(test_path, header=None)\n",
    "    y_test = df.iloc[:, 0].to_numpy()\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "    X_test = xgboost.DMatrix(df.values)\n",
    "    #Run Predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    #Evaluate Predictions\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    report_dict = {\n",
    "        \"classification_metrics\": {\n",
    "            \"auc_score\": {\n",
    "                \"value\": auc_score,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    #Save Evaluation Report\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77f03edb-607c-457d-a49b-52cba35dd13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model evaluation step to evaluate the trained model\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"script-churn-eval\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "eval_args = script_eval.run(\n",
    "     inputs=[\n",
    "            ProcessingInput(\n",
    "                source=step_tuning.get_top_model_s3_uri(top_k=0,s3_bucket=default_bucket,prefix=\"output\"),\n",
    "                destination=\"/opt/ml/processing/model\"\n",
    "            ),\n",
    "            ProcessingInput(\n",
    "                source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"test\"\n",
    "                ].S3Output.S3Uri,\n",
    "                destination=\"/opt/ml/processing/test\"\n",
    "            )\n",
    "        ],\n",
    "    outputs=[\n",
    "            ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\",\\\n",
    "                             destination=f\"s3://{default_bucket}/output/evaluation\"),\n",
    "        ],\n",
    "    code=f\"pipeline_scripts/churn_evaluate.py\",\n",
    ")\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"ChurnEvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"ChurnEvalModel\",\n",
    "    step_args=eval_args,\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeec8d7-f344-419f-b492-c326f0db7a72",
   "metadata": {},
   "source": [
    "## 5. Model Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8aa1781a-e8f9-4c23-90e3-b1f04d51f24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import Model\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=step_tuning.get_top_model_s3_uri(top_k=0,s3_bucket=default_bucket,prefix=\"output\"),\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "register_args = model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    ")\n",
    "step_register = ModelStep(name=\"ChurnRegisterModel\", step_args=register_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eceec5d-aa62-4e42-9d0c-c946813c74a6",
   "metadata": {},
   "source": [
    "## 6. Conditional Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f05a6d32-34ad-4e26-a4c6-9b89ff284990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionGreaterThan\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "cond_lte = ConditionGreaterThan(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"classification_metrics.auc_score.value\",\n",
    "    ),\n",
    "    right=auc_score_threshold,\n",
    ")\n",
    "step_cond = ConditionStep(\n",
    "    name=\"CheckAUCScoreChurnEvaluation\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbf0dd4-8bdd-4ab5-b1de-53e0890168ee",
   "metadata": {},
   "source": [
    "## 7. Building Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89956097-1837-45de-8376-1a1106ac462a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'HyperParameterTuningJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Version': '2020-12-01', 'Metadata': {}, 'Parameters': [{'Name': 'ProcessingInstanceCount', 'Type': 'Integer', 'DefaultValue': 1}, {'Name': 'ProcessingInstanceType', 'Type': 'String', 'DefaultValue': 'ml.m5.xlarge'}, {'Name': 'TrainingInstanceType', 'Type': 'String', 'DefaultValue': 'ml.m5.xlarge'}, {'Name': 'ModelApprovalStatus', 'Type': 'String', 'DefaultValue': 'PendingManualApproval'}], 'PipelineExperimentConfig': {'ExperimentName': {'Get': 'Execution.PipelineName'}, 'TrialName': {'Get': 'Execution.PipelineExecutionId'}}, 'Steps': [{'Name': 'ChurnModelProcess', 'Type': 'Processing', 'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.xlarge', 'InstanceCount': {'Get': 'Parameters.ProcessingInstanceCount'}, 'VolumeSizeInGB': 30}}, 'AppSpecification': {'ImageUri': '366743142698.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-scikit-learn:1.0-1-cpu-py3', 'ContainerEntrypoint': ['python3', '/opt/ml/processing/input/code/churn_preprocess.py']}, 'RoleArn': 'arn:aws:iam::185567426878:role/service-role/AmazonSageMaker-ExecutionRole-20241019T223226', 'ProcessingInputs': [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-ap-northeast-2-185567426878/sagemaker-train-pipeline/ChurnModelProcess/input/input-1/storedata_total.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-ap-northeast-2-185567426878/sagemaker-train-pipeline/code/87546b483931a742a5dcebd7f8e5c9e3/churn_preprocess.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-ap-northeast-2-185567426878/output/train', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'validation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-ap-northeast-2-185567426878/output/validation', 'LocalPath': '/opt/ml/processing/validation', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-ap-northeast-2-185567426878/output/test', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}]}}}, {'Name': 'ChurnHyperParameterTuning', 'Type': 'Tuning', 'Arguments': {'HyperParameterTuningJobConfig': {'Strategy': 'Bayesian', 'ResourceLimits': {'MaxNumberOfTrainingJobs': 2, 'MaxParallelTrainingJobs': 2}, 'TrainingJobEarlyStoppingType': 'Off', 'HyperParameterTuningJobObjective': {'Type': 'Maximize', 'MetricName': 'validation:auc'}, 'ParameterRanges': {'ContinuousParameterRanges': [{'Name': 'eta', 'MinValue': '0', 'MaxValue': '1', 'ScalingType': 'Auto'}, {'Name': 'min_child_weight', 'MinValue': '1', 'MaxValue': '10', 'ScalingType': 'Auto'}, {'Name': 'alpha', 'MinValue': '0', 'MaxValue': '2', 'ScalingType': 'Auto'}], 'CategoricalParameterRanges': [], 'IntegerParameterRanges': [{'Name': 'max_depth', 'MinValue': '1', 'MaxValue': '10', 'ScalingType': 'Auto'}]}}, 'TrainingJobDefinition': {'StaticHyperParameters': {'eval_metric': 'auc', 'objective': 'binary:logistic', 'num_round': '100', 'rate_drop': '0.3', 'tweedie_variance_power': '1.4'}, 'RoleArn': 'arn:aws:iam::185567426878:role/service-role/AmazonSageMaker-ExecutionRole-20241019T223226', 'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-ap-northeast-2-185567426878/output'}, 'StoppingCondition': {'MaxRuntimeInSeconds': 86400}, 'HyperParameterTuningResourceConfig': {'InstanceCount': 1, 'InstanceType': {'Get': 'Parameters.TrainingInstanceType'}, 'VolumeSizeInGB': 30}, 'AlgorithmSpecification': {'TrainingInputMode': 'File', 'TrainingImage': '366743142698.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3'}, 'InputDataConfig': [{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': {'Get': \"Steps.ChurnModelProcess.ProcessingOutputConfig.Outputs['train'].S3Output.S3Uri\"}, 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv', 'ChannelName': 'train'}, {'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': {'Get': \"Steps.ChurnModelProcess.ProcessingOutputConfig.Outputs['validation'].S3Output.S3Uri\"}, 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv', 'ChannelName': 'validation'}]}}}, {'Name': 'ChurnEvalModel', 'Type': 'Processing', 'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': {'Get': 'Parameters.ProcessingInstanceType'}, 'InstanceCount': 1, 'VolumeSizeInGB': 30}}, 'AppSpecification': {'ImageUri': '366743142698.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3', 'ContainerEntrypoint': ['python3', '/opt/ml/processing/input/code/churn_evaluate.py']}, 'RoleArn': 'arn:aws:iam::185567426878:role/service-role/AmazonSageMaker-ExecutionRole-20241019T223226', 'ProcessingInputs': [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': {'Std:Join': {'On': '/', 'Values': ['s3:/', 'sagemaker-ap-northeast-2-185567426878', 'output', {'Get': 'Steps.ChurnHyperParameterTuning.TrainingJobSummaries[0].TrainingJobName'}, 'output/model.tar.gz']}}, 'LocalPath': '/opt/ml/processing/model', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': {'Get': \"Steps.ChurnModelProcess.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri\"}, 'LocalPath': '/opt/ml/processing/test', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-ap-northeast-2-185567426878/sagemaker-train-pipeline/code/bd93ca287b616f7d22d33f38eee6f0cd/churn_evaluate.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'evaluation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-ap-northeast-2-185567426878/output/evaluation', 'LocalPath': '/opt/ml/processing/evaluation', 'S3UploadMode': 'EndOfJob'}}]}}, 'PropertyFiles': [{'PropertyFileName': 'ChurnEvaluationReport', 'OutputName': 'evaluation', 'FilePath': 'evaluation.json'}]}, {'Name': 'CheckAUCScoreChurnEvaluation', 'Type': 'Condition', 'Arguments': {'Conditions': [{'Type': 'GreaterThan', 'LeftValue': {'Std:JsonGet': {'PropertyFile': {'Get': 'Steps.ChurnEvalModel.PropertyFiles.ChurnEvaluationReport'}, 'Path': 'classification_metrics.auc_score.value'}}, 'RightValue': 0.75}], 'IfSteps': [{'Name': 'ChurnRegisterModel-RegisterModel', 'Type': 'RegisterModel', 'Arguments': {'ModelPackageGroupName': 'ChurnModelPackageGroup', 'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json', 'S3Uri': 's3://sagemaker-ap-northeast-2-185567426878/output/evaluation/evaluation.json'}}, 'Bias': {}, 'Explainability': {}}, 'InferenceSpecification': {'Containers': [{'Image': '366743142698.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3', 'Environment': {}, 'ModelDataUrl': {'Std:Join': {'On': '/', 'Values': ['s3:/', 'sagemaker-ap-northeast-2-185567426878', 'output', {'Get': 'Steps.ChurnHyperParameterTuning.TrainingJobSummaries[0].TrainingJobName'}, 'output/model.tar.gz']}}}], 'SupportedContentTypes': ['text/csv'], 'SupportedResponseMIMETypes': ['text/csv'], 'SupportedRealtimeInferenceInstanceTypes': ['ml.t2.medium', 'ml.m5.xlarge'], 'SupportedTransformInstanceTypes': ['ml.m5.xlarge']}, 'ModelApprovalStatus': {'Get': 'Parameters.ModelApprovalStatus'}, 'SkipModelValidation': 'None'}}], 'ElseSteps': []}}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_count,\n",
    "        processing_instance_type,\n",
    "        training_instance_type,\n",
    "        model_approval_status,\n",
    "        input_data,\n",
    "        auc_score_threshold,\n",
    "    ],\n",
    "    steps=[step_process, step_tuning, step_eval, step_cond],\n",
    ") \n",
    "definition = json.loads(pipeline.definition())\n",
    "print(definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0703f56f-2e14-4a4a-9723-760abee0ce97",
   "metadata": {},
   "source": [
    "## Start Pipeline execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "764ed988-9fca-46ca-a01b-61244a15f74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'HyperParameterTuningJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_PipelineExecution(arn='arn:aws:sagemaker:ap-northeast-2:185567426878:pipeline/sagemaker-train-pipeline/execution/sei07uh22jac', sagemaker_session=<sagemaker.session.Session object at 0x7f28a536e390>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)\n",
    "\n",
    "pipeline.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
